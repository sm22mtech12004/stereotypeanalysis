{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This script is designed to identify sentences in a PDF document that may contain stereotypical content related to women**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stereotyped Sentence: Please tell meit’s not Deeply\n",
      "Sensitive Emo-Dude\n",
      "—who says things like “Ilove\n",
      "strong women.”\n",
      "NICK\n",
      "Code for ‘~Ihate strong women.”\n",
      "\n",
      "Stereotyped Sentence: Iknow afew\n",
      "housewives, that evening glass of\n",
      "wine starts coming atnoon.\n",
      "Stereotyped Sentence: Wehear MARYBETH’s TONE onthe other end: FEMALE; ANGRY.\n",
      "\n",
      "Stereotyped Sentence: BILL DUNNE, 60s, bedraggled, ismuttering tohimself while a\n",
      "quietly FURIOUS FEMALE officer waits with him.\n",
      "\n",
      "Stereotyped Sentence: GG —Yellow Revisions 9/27/13 25.\n",
      "FEMALE OFFICER\n",
      "Really?\n",
      "Stereotyped Sentence: FEMALE OFFICER\n",
      "Your father wandered out ofComfort\n",
      "Hill this morning.\n",
      "Stereotyped Sentence: FEMALE OFFICER\n",
      "Sir, please don’t take that tone\n",
      "with me.\n",
      "\n",
      "Stereotyped Sentence: I’ve sworn never tobeone ofthose *\n",
      "wives.\n",
      "Stereotyped Sentence: Wives\n",
      "whotreat their men like hapless *\n",
      "puppies: tobetrained and broken.\n",
      "\n",
      "Stereotyped Sentence: NICK\n",
      "Husbands who treat their wives like\n",
      "eccentric dictators: tobeappeased *\n",
      "and contained.\n",
      "Stereotyped Sentence: Women pile out.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import PyPDF2\n",
    "\n",
    "# Step 1: Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Step 2: Load and Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(min(50, len(reader.pages))):  # Only process the first 50 pages\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"GoneGirl.pdf\")\n",
    "\n",
    "# Step 3: Process Text with Spacy\n",
    "doc = nlp(pdf_text)\n",
    "\n",
    "# Step 4: Identify Potentially Stereotyped Sentences\n",
    "stereotyped_sentences = []\n",
    "stereotype_keywords = [\"women\", \"female\", \"wives\", \"girls\", \"mothers\"]  # Add more relevant keywords\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    if any(keyword in sentence.text.lower() for keyword in stereotype_keywords):\n",
    "        stereotyped_sentences.append(sentence.text)\n",
    "\n",
    "# Step 5: Print or Save the Results\n",
    "for sentence in stereotyped_sentences:\n",
    "    print(f\"Stereotyped Sentence: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The code you provided is designed to analyze stereotyped sentences and generate a description or classification for each sentence using a pre-trained model from the Hugging Face Transformers library.**\n",
    "**The output classification (e.g., \"positive\", \"negative\") should be interpreted in the context of stereotypes. For instance, a \"negative\" label might indicate a sentence that reinforces a harmful stereotype, while a \"positive\" label might suggest the opposite.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac14d9ef9434392ab57e086b4429ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sneha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sneha\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50919f8840c43e79408543e7726dbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc7dad2cdfe475cb52d20e6f13db3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9892bb42e8bc485a83dbd1912fa67265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stereotype descriptions have been saved to 'stereotype_analysis.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Load the JSON file containing the stereotyped sentences\n",
    "with open(\"stereotyped_sentences.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Step 2: Load a pre-trained model for text generation or analysis\n",
    "# You can use Hugging Face's transformers library\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Step 3: Process each sentence to generate a description of the stereotype\n",
    "stereotype_analysis = []\n",
    "\n",
    "for sentence in data['stereotyped_sentences']:\n",
    "    description = classifier(sentence)\n",
    "    stereotype_analysis.append({\n",
    "        \"sentence\": sentence,\n",
    "        \"stereotype_description\": description\n",
    "    })\n",
    "\n",
    "# Step 4: Save the results to a new JSON file\n",
    "with open(\"stereotype_analysis.json\", \"w\") as json_output_file:\n",
    "    json.dump(stereotype_analysis, json_output_file, indent=4)\n",
    "\n",
    "print(\"Stereotype descriptions have been saved to 'stereotype_analysis.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This analysis can provide insights into the gender dynamics in the text by highlighting which sentences are dominated by male or female-related terms and actions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'gender_dominance_sentences.json'\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import PyPDF2\n",
    "import json\n",
    "\n",
    "# Step 1: Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Step 2: Load and Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(min(50, len(reader.pages))):  # Only process the first 50 pages\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"GoneGirl.pdf\")\n",
    "\n",
    "# Step 3: Define Keywords and Indicators\n",
    "male_keywords = [\"he\", \"man\", \"men\", \"husband\", \"father\", \"male\"]\n",
    "female_keywords = [\"she\", \"woman\", \"women\", \"wife\", \"mother\", \"female\"]\n",
    "male_actions = [\"lead\", \"command\", \"control\", \"dominate\", \"decide\"]\n",
    "female_actions = [\"care\", \"nurture\", \"support\", \"assist\", \"empathize\"]\n",
    "\n",
    "# Step 4: Function to Analyze Sentence Dominance\n",
    "def analyze_gender_dominance(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "    for token in doc:\n",
    "        if token.lemma_ in male_keywords:\n",
    "            male_count += 1\n",
    "        elif token.lemma_ in female_keywords:\n",
    "            female_count += 1\n",
    "        elif token.lemma_ in male_actions:\n",
    "            male_count += 1\n",
    "        elif token.lemma_ in female_actions:\n",
    "            female_count += 1\n",
    "\n",
    "    if male_count > female_count:\n",
    "        return \"Male Dominated\"\n",
    "    elif female_count > male_count:\n",
    "        return \"Female Dominated\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Step 5: Process Text with Spacy and Analyze Each Sentence\n",
    "doc = nlp(pdf_text)\n",
    "results = {\"Male Dominated\": [], \"Female Dominated\": [], \"Neutral\": []}\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    dominance = analyze_gender_dominance(sentence.text)\n",
    "    results[dominance].append(sentence.text)\n",
    "\n",
    "# Step 6: Save the Results to a JSON file\n",
    "with open(\"gender_dominance_sentences.json\", \"w\") as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "\n",
    "print(\"Results saved to 'gender_dominance_sentences.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**EXAMPLE 1]This script is designed to analyze a PDF file and identify sentences that may contain misogynistic content or negative portrayals of females. It uses specific keywords and actions to classify sentences and saves the results to a JSON file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misogynistic Sentence: AMY\n",
      "Soifyouwrite for amen’s\n",
      "magazine, does that make you an\n",
      "expert onbeing aman?\n",
      "NICK\n",
      "Intheory, Iknow what men drink,\n",
      "what men wear-\n",
      "AMY\n",
      "How menbullshit.\n",
      "\n",
      "Misogynistic Sentence: He *\n",
      "hits OFF.\n",
      "Negative Female Portrayal Sentence: *\n",
      "Howshitty and small she made me\n",
      "feel all the time.\n",
      "Negative Female Portrayal Sentence: I\n",
      "came home every day, and mystomach\n",
      "would hurt, because Iknew she’d be *\n",
      "there.\n",
      "Misogynistic Sentence: Look, just\n",
      "because the guyisn’t weeping,\n",
      "doesn’t mean he’s not hurting.\n",
      "\n",
      "Negative Female Portrayal Sentence: Onthe TVcomes awedding portrait ofNICK and ANY.\n",
      "GILPIN (CONT’D)\n",
      "Mywife says hekilled her.\n",
      "\n",
      "Misogynistic Sentence: This man ofmine maykill me.\n",
      "Negative Female Portrayal Sentence: Assoon ashehits the corner,\n",
      "She starts staging her murder scene: tossing tables,\n",
      "upturning the ottoman.\n",
      "Negative Female Portrayal Sentence: The world will hate Nick for\n",
      "killing hisbeautiful, pregnant\n",
      "wife.\n",
      "Negative Female Portrayal Sentence: -That Nick dumped his beloved like *\n",
      "garbage, and shefloated down past *\n",
      "all the other abused, unwanted,\n",
      "inconvenient women.\n",
      "\n",
      "Negative Female Portrayal Sentence: She takes out ahammer,\n",
      "sizes upher cheek, HITS herself, once, twice.\n",
      "\n",
      "Negative Female Portrayal Sentence: Amy got pregnant, Igot angry,\n",
      "killed her and the baby.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Step 1: Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Step 2: Load and Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(min(100, len(reader.pages))):  # Only process the first 50 pages\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"GoneGirl.pdf\")\n",
    "\n",
    "# Step 3: Define Keywords and Negative Actions\n",
    "male_keywords = [\"he\", \"man\", \"men\", \"husband\", \"father\", \"male\"]\n",
    "female_keywords = [\"she\", \"woman\", \"women\", \"wife\", \"mother\", \"female\"]\n",
    "negative_actions = [\"kill\", \"abuse\", \"hurt\", \"hit\", \"demean\", \"insult\", \"disrespect\"]\n",
    "\n",
    "# Step 4: Function to Analyze Misogynistic Content in a Sentence\n",
    "def analyze_misogyny(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.lemma_ in male_keywords:\n",
    "            for action in negative_actions:\n",
    "                if action in sentence.lower():\n",
    "                    return \"Misogynistic\"\n",
    "        elif token.lemma_ in female_keywords:\n",
    "            for action in negative_actions:\n",
    "                if action in sentence.lower():\n",
    "                    return \"Negative Female Portrayal\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "# Step 5: Split Text into Sentences and Analyze\n",
    "doc = nlp(pdf_text)\n",
    "misogynistic_results = []\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    analysis = analyze_misogyny(sentence.text)\n",
    "    if analysis in [\"Misogynistic\", \"Negative Female Portrayal\"]:\n",
    "        misogynistic_results.append({\n",
    "            \"sentence\": sentence.text,\n",
    "            \"classification\": analysis\n",
    "        })\n",
    "\n",
    "# Step 6: Save the Results to a JSON File\n",
    "import json\n",
    "with open(\"misogynistic_sentences.json\", \"w\") as json_file:\n",
    "    json.dump(misogynistic_results, json_file, indent=4)\n",
    "\n",
    "# Step 7: Print the Results\n",
    "for result in misogynistic_results:\n",
    "    print(f\"{result['classification']} Sentence: {result['sentence']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**EXAMPLE 2] This script is designed to analyze a PDF file and identify sentences that may contain misogynistic content or negative portrayals of females. It uses specific keywords and actions to classify sentences and saves the results to a JSON file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misogynistic Sentence: His demeanor suggests that he’s in \n",
      "great denial.\n",
      "Negative Female Portrayal Sentence: She is boiling with rage, \n",
      "but...this has also hit her somewhere deep.\n",
      "Negative Female Portrayal Sentence: Confused by Joan’s demeanor (and her presence), Annie warily \n",
      "begins to push her cart toward her.\n",
      "\n",
      "Negative Female Portrayal Sentence: As she walks toward the door:\n",
      "JOAN\n",
      "You didn’t kill her, Annie.\n",
      "\n",
      "Negative Female Portrayal Sentence: ANNIE\n",
      "I didn’t kill her!\n",
      "\n",
      "Negative Female Portrayal Sentence: She goes white.\n",
      "Misogynistic Sentence: Uh - because my daughter was killed \n",
      "and now my psychiatrist husband is \n",
      "calling over his peers to \n",
      "investigate me.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Step 1: Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Step 2: Load and Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(min(100, len(reader.pages))):  # Only process the first 50 pages\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"HEREDITARY.pdf\")\n",
    "\n",
    "# Step 3: Define Keywords and Negative Actions\n",
    "male_keywords = [\"he\", \"man\", \"men\", \"husband\", \"father\", \"male\"]\n",
    "female_keywords = [\"she\", \"woman\", \"women\", \"wife\", \"mother\", \"female\"]\n",
    "negative_actions = [\"kill\", \"abuse\", \"hurt\", \"hit\", \"demean\", \"insult\", \"disrespect\"]\n",
    "\n",
    "# Step 4: Function to Analyze Misogynistic Content in a Sentence\n",
    "def analyze_misogyny(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if token.lemma_ in male_keywords:\n",
    "            for action in negative_actions:\n",
    "                if action in sentence.lower():\n",
    "                    return \"Misogynistic\"\n",
    "        elif token.lemma_ in female_keywords:\n",
    "            for action in negative_actions:\n",
    "                if action in sentence.lower():\n",
    "                    return \"Negative Female Portrayal\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "# Step 5: Split Text into Sentences and Analyze\n",
    "doc = nlp(pdf_text)\n",
    "misogynistic_results = []\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    analysis = analyze_misogyny(sentence.text)\n",
    "    if analysis in [\"Misogynistic\", \"Negative Female Portrayal\"]:\n",
    "        misogynistic_results.append({\n",
    "            \"sentence\": sentence.text,\n",
    "            \"classification\": analysis\n",
    "        })\n",
    "\n",
    "# Step 6: Save the Results to a JSON File\n",
    "import json\n",
    "with open(\"misogynistic_sentences.json\", \"w\") as json_file:\n",
    "    json.dump(misogynistic_results, json_file, indent=4)\n",
    "\n",
    "# Step 7: Print the Results\n",
    "for result in misogynistic_results:\n",
    "    print(f\"{result['classification']} Sentence: {result['sentence']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**This script is designed to extract text from a PDF file and analyze each sentence to determine whether it reflects \"Female Weakness\" or \"Male Dominance\" based on predefined keywords. It saves the results to a JSON file and prints them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female Weakness--------------- Sentence: Please tell meit’s not Deeply\n",
      "Sensitive Emo-Dude\n",
      "—who says things like “Ilove\n",
      "strong women.”\n",
      "NICK\n",
      "Code for ‘~Ihate strong women.”\n",
      "\n",
      "Female Weakness--------------- Sentence: A.Your fingers arefar too *\n",
      "delicate forreal scrimshaw work.\n",
      "\n",
      "Female Weakness--------------- Sentence: NEW YORK BOOKSTORE -STACKS -DAY 39\n",
      "Nick iswearing abackpack, holding anAmy-blue CLUE ashe\n",
      "makes his way; Amy follows, all grins.\n",
      "\n",
      "Female Weakness--------------- Sentence: GO\n",
      "When you’re upset, youbottle up.\n",
      "\n",
      "Female Weakness--------------- Sentence: NICK\n",
      "Great, I’ll try tobalance onthe\n",
      "exact edge ofyour emotional razor.\n",
      "\n",
      "Male Dominance--------------- Sentence: 54\n",
      "BONEY leads the ELLIOTTS and NICK into aroom ofaHALF DOZEN\n",
      "BORED LOCAL REPORTERS:\n",
      "Female Weakness--------------- Sentence: Now Amy needs your help.\n",
      "Female Weakness--------------- Sentence: Wesee the words aswehear:\n",
      "AMY (V.0.)\n",
      "Want totest your marriage for weak\n",
      "spots?\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "# Step 1: Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Step 2: Load and Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(min(50, len(reader.pages))):  # Only process the first 50 pages\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"GoneGirl.pdf\")\n",
    "\n",
    "# Step 3: Define Comprehensive Keywords for Weakness and Dominance\n",
    "female_weakness_keywords = [\n",
    "    \"needs\", \"depends on\", \"relies on\", \"requires help\", \"seeks help\", \"pleads\", \"asks for help\", \"depends upon\",\n",
    "    \"submits\", \"obeys\", \"yields\", \"follows\", \"compliant\", \"docile\", \"subservient\", \"acquiesces\",\n",
    "    \"hysterical\", \"emotional\", \"overwhelmed\", \"fragile\", \"vulnerable\", \"sensitive\", \"teary\", \"upset\",\n",
    "    \"weak\", \"delicate\", \"frail\", \"helpless\", \"powerless\", \"feeble\", \"timid\", \"faint\",\n",
    "    \"unable\", \"powerless\", \"helpless\", \"victim\", \"trapped\", \"cornered\", \"defenseless\", \"dependent\",\n",
    "    \"housewife\", \"caregiver\", \"nurturer\", \"homebound\", \"domestic\", \"motherly\", \"housebound\", \"homemaker\"\n",
    "]\n",
    "\n",
    "male_dominance_keywords = [\n",
    "    \"controls\", \"dominates\", \"commands\", \"leads\", \"rules\", \"manages\", \"governs\", \"directs\",\n",
    "    \"strong\", \"powerful\", \"unshakeable\", \"stoic\", \"invincible\", \"mighty\", \"tough\", \"robust\",\n",
    "    \"forces\", \"demands\", \"imposes\", \"asserts\", \"threatens\", \"intimidates\", \"coerces\", \"bullies\",\n",
    "    \"authority\", \"superior\", \"in charge\", \"decision-maker\", \"commander\", \"chief\", \"boss\",\n",
    "    \"self-reliant\", \"independent\", \"autonomous\", \"stands alone\", \"self-sufficient\", \"self-made\", \"unassisted\",\n",
    "    \"assertive\", \"confident\", \"bold\", \"unwavering\", \"decisive\", \"determined\", \"firm\", \"resolute\"\n",
    "]\n",
    "\n",
    "# Step 4: Function to Analyze Dominance Content in a Sentence\n",
    "def analyze_dominance(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        if any(keyword in sentence.lower() for keyword in female_weakness_keywords):\n",
    "            return \"Female Weakness\"\n",
    "        elif any(keyword in sentence.lower() for keyword in male_dominance_keywords):\n",
    "            return \"Male Dominance\"\n",
    "    return \"Neutral\"\n",
    "\n",
    "# Step 5: Split Text into Sentences and Analyze\n",
    "doc = nlp(pdf_text)\n",
    "dominance_results = []\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    analysis = analyze_dominance(sentence.text)\n",
    "    if analysis in [\"Female Weakness\", \"Male Dominance\"]:\n",
    "        dominance_results.append({\n",
    "            \"sentence\": sentence.text,\n",
    "            \"classification\": analysis\n",
    "        })\n",
    "\n",
    "# Step 6: Save the Results to a JSON File\n",
    "import json\n",
    "with open(\"dominance_sentences.json\", \"w\") as json_file:\n",
    "    json.dump(dominance_results, json_file, indent=4)\n",
    "\n",
    "# Step 7: Print the Results\n",
    "for result in dominance_results:\n",
    "    print(f\"{result['classification']}--------------- Sentence: {result['sentence']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This script is designed to extract text from a PDF document (up to 50 pages) and analyze each sentence to detect whether it contains both female-related keywords and words associated with female weakness. If both types of keywords are present in a sentence, it marks the sentence as exhibiting \"Female Weakness\" and stores it in a JSON file.No use of word2Vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marked Sentence: Please tell meit’s not Deeply\n",
      "Sensitive Emo-Dude\n",
      "—who says things like “Ilove\n",
      "strong women.”\n",
      "NICK\n",
      "Code for ‘~Ihate strong women.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import PyPDF2\n",
    "import json\n",
    "\n",
    "# Step 1: Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Step 2: Load and Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(min(50, len(reader.pages))):  # Only process the first 50 pages\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"GoneGirl.pdf\")\n",
    "\n",
    "# Step 3: Define Keywords\n",
    "female_keywords = [\"woman\", \"women\", \"female\", \"girl\", \"girls\", \"lady\", \"ladies\", \"wife\", \"wives\", \"mother\", \"mothers\", \"daughter\", \"daughters\"]\n",
    "female_weakness_keywords = [\n",
    "    \"needs\", \"depends on\", \"relies on\", \"requires help\", \"seeks help\", \"pleads\", \"asks for help\", \"depends upon\",\n",
    "    \"submits\", \"obeys\", \"yields\", \"follows\", \"compliant\", \"docile\", \"subservient\", \"acquiesces\",\n",
    "    \"hysterical\", \"emotional\", \"overwhelmed\", \"fragile\", \"vulnerable\", \"sensitive\", \"teary\", \"upset\",\n",
    "    \"weak\", \"delicate\", \"frail\", \"helpless\", \"powerless\", \"feeble\", \"timid\", \"faint\",\n",
    "    \"unable\", \"powerless\", \"helpless\", \"victim\", \"trapped\", \"cornered\", \"defenseless\", \"dependent\",\n",
    "    \"housewife\", \"caregiver\", \"nurturer\", \"homebound\", \"domestic\", \"motherly\", \"housebound\", \"homemaker\"\n",
    "]\n",
    "\n",
    "# Step 4: Function to Analyze if a Sentence Contains Both Female and Weakness Keywords\n",
    "def analyze_female_weakness(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    has_female_keyword = any(keyword in sentence.lower() for keyword in female_keywords)\n",
    "    has_weakness_keyword = any(keyword in sentence.lower() for keyword in female_weakness_keywords)\n",
    "    \n",
    "    if has_female_keyword and has_weakness_keyword:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Step 5: Split Text into Sentences and Analyze\n",
    "doc = nlp(pdf_text)\n",
    "female_weakness_results = []\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    if analyze_female_weakness(sentence.text):\n",
    "        female_weakness_results.append({\n",
    "            \"sentence\": sentence.text,\n",
    "            \"classification\": \"Female Weakness\"\n",
    "        })\n",
    "\n",
    "# Step 6: Save the Results to a JSON File\n",
    "with open(\"female_weakness_sentences.json\", \"w\") as json_file:\n",
    "    json.dump(female_weakness_results, json_file, indent=4)\n",
    "\n",
    "# Step 7: Print the Results\n",
    "for result in female_weakness_results:\n",
    "    print(f\"Marked Sentence: {result['sentence']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\sneha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\sneha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\sneha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sneha\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Downloading gensim-4.3.3-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 24.0/24.0 MB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\sneha\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This below script is designed to analyze a PDF document (specifically, the first 50 pages) and identify sentences that contain both keywords related to females and keywords associated with female weakness. The goal is to detect sentences that potentially exhibit stereotypical or biased representations of women.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marked Sentence: NO PORTION OF THIS SCRIPT MAY BE PERFORMED, PUBLISHED, \n",
      "REPRODUCED, SOLD OR DISTRIBUTED BY ANY MEANS, OR QUOTED OR PUBLISHED \n",
      "IN ANY MEDIUM, INCLUDING ON ANY WEB SITE, WITHOUT THE PRIOR WRITTEN CONSENT OF TWENTIETH CENTURY FOX FILM CORPORATION.\n",
      "Marked Sentence: DISPOSAL OF THIS \n",
      "SCRIPT COPY DOES NOT ALTER ANY OF THE RESTRICTIONS SET FORTH ABOVE.\n",
      "   \n",
      "Marked Sentence: Ipicture cracking her lovely\n",
      "skull, unspooling her brain,\n",
      "Nick runs his fingers into Amy’s hair.\n",
      "\n",
      "Marked Sentence: Trying toget answers.\n",
      "\n",
      "Marked Sentence: What have wedone toeach\n",
      "other?\n",
      "AMY wakes, turns, gives alook ofalarm.\n",
      "Marked Sentence: NORTH CARTHAGE -MORNING 2\n",
      "Acarved faux-marble entry—reading FOREST GLEN—ushers usinto\n",
      "aruined HOUSING DEVELOPMENT.\n",
      "Marked Sentence: Afew\n",
      "Fourth ofJuly decorations hang inwindows.\n",
      "Marked Sentence: 2.\n",
      "Heturns and stares back athis HOUSE asifgirding himself.\n",
      "\n",
      "Marked Sentence: His shadowy\n",
      "figure fills the doorway for amoment.\n",
      "Marked Sentence: THE BAR -DAY 5\n",
      "Nick’s twin sister, GO, 30s, nerdy-hot, iswashing mugs.\n",
      "Marked Sentence: The\n",
      "bar ispacked with ‘80s k±tsch: board games, toys, posters.\n",
      "\n",
      "Marked Sentence: Hesits onthe bar’s customer side.\n",
      "Marked Sentence: Ihated this game!\n",
      "\n",
      "Marked Sentence: Shetries towait him out.\n",
      "Marked Sentence: GO(CONT’D)Ifyou don’t talk, I’llfill the\n",
      "silence with: anExcruciating Story\n",
      "byMargo Dunne.\n",
      "\n",
      "Marked Sentence: This isanold, reliable routine.\n",
      "GO(CONT’D)\n",
      "Icould tell you about mycustomer—\n",
      "service experience while changing\n",
      "Internet providers.\n",
      "Marked Sentence: GO\n",
      "Orthe time Isaw awoman who\n",
      "looked exactly like myfriend\n",
      "Monica butitwasn’t Monica, itwas\n",
      "astranger—\n",
      "NICK\n",
      "—whose name was.. .Monica.\n",
      "\n",
      "Marked Sentence: The pen isGIRLY,\n",
      "topped with pink feathers.\n",
      "Marked Sentence: Wesee atthe top: January 8,\n",
      "2005.\n",
      "Marked Sentence: She spots her FRIEND deep-flirting aguy, and stops midway,\n",
      "stuck with TWO BEERS.\n",
      "Marked Sentence: She makes her way toward atable with\n",
      "picked—over food and scans the room for anyone she knows.\n",
      "Marked Sentence: It’s dangerous toset down amonk— *\n",
      "brewed Belgian wheat beer when the *\n",
      "party isdown tothree Beast Lites\n",
      "and abottle ofPucker.\n",
      "\n",
      "Marked Sentence: Hegestures toward agroup ofWilliamsburg musician-types:\n",
      "suspenders and broad-brimmed hats.\n",
      "\n",
      "Marked Sentence: Finally, someone totell mehow to\n",
      "pronounce that word.\n",
      "\n",
      "Marked Sentence: One syllable.\n",
      "\n",
      "Marked Sentence: *\n",
      "(moving closer toher, so *\n",
      "they have same POV) *\n",
      "\n",
      "Marked Sentence: *\n",
      "They scan the crowd together.\n",
      "Marked Sentence: Nick points toahorn-\n",
      "rimmed, haughty DOUCHEBAG.\n",
      "Marked Sentence: *\n",
      "Nick points toasideburned guy inaNOVELTY TEE.\n",
      "Marked Sentence: *\n",
      "Nick points toawavy-haired granola-yoga type.\n",
      "Marked Sentence: Please tell meit’s not Deeply\n",
      "Sensitive Emo-Dude\n",
      "—who says things like “Ilove\n",
      "strong women.”\n",
      "NICK\n",
      "Code for ‘~Ihate strong women.”\n",
      "\n",
      "Marked Sentence: Abeat asthey scan the room, then face each other.\n",
      "Marked Sentence: Ah: native New Yorker!GG —Yellow Revisions 9/27/13 6.\n",
      "AMY\n",
      "World ends atthe Hudson.\n",
      "Marked Sentence: Who are you?\n",
      "AMY\n",
      "A.Iamanaward—winning\n",
      "scrimshander.\n",
      "Marked Sentence: C.Iwrite\n",
      "personality quizzes for magazines.\n",
      "\n",
      "Marked Sentence: A.Your fingers arefar too *\n",
      "delicate forreal scrimshaw work.\n",
      "\n",
      "Marked Sentence: B.Iamacharter subscriber to *\n",
      "Middling Warlord Weekly—I’m sure\n",
      "I’d recognize you.\n",
      "Marked Sentence: I’m the guy tosave you from all *\n",
      "this awesomeness.\n",
      "\n",
      "Marked Sentence: APARTMENT ELEVATOR -NIGHT 8\n",
      "They head down: tipsy, not touching, but thinking about it.\n",
      "\n",
      "Marked Sentence: She stops, studies him.\n",
      "Marked Sentence: AMY\n",
      "It’s hard tobelieve you.\n",
      "Marked Sentence: BROOKLYN -NIGHT 9\n",
      "They are huddling together, walking tohail acab.\n",
      "\n",
      "Marked Sentence: NICK\n",
      "Ilove New York parties because I *\n",
      "get toleave and walk outinto New *\n",
      "York.\n",
      "Marked Sentence: They turn the corner and step into acloud ofpowdered sugar\n",
      "asit’s funneled into abakery.\n",
      "Marked Sentence: ASUGAR SNOWSTORM.\n",
      "Marked Sentence: Nick\n",
      "grins: Like this!\n",
      "NICK (CONT’D)\n",
      "\n",
      "Marked Sentence: You know Ihave tokiss you now.\n",
      "\n",
      "Marked Sentence: Iwould beafool tolet you walk\n",
      "through asugar storm unkissed.\n",
      "Marked Sentence: BARS onthe\n",
      "windows.\n",
      "Marked Sentence: THE BAR -DAY 11\n",
      "The Master Mind sits untouched as GOsets upLIFE.\n",
      "\n",
      "Marked Sentence: GO\n",
      "SoisAmy going todoone ofher\n",
      "anniversary—whaddaya call it?—\n",
      "treasure hunts?\n",
      "\n",
      "Marked Sentence: You mean the forced march designed\n",
      "topoint out what anuncaring,\n",
      "oblivious asshole Iam.\n",
      "GO\n",
      "Wow.\n",
      "Silence.\n",
      "Marked Sentence: ~‘When your poor Amy has acold;\n",
      "this dessert just must besold.”\n",
      "\n",
      "Marked Sentence: She led meto *\n",
      "the dying rosebush inour backyard.\n",
      "\n",
      "Marked Sentence: Bet mygutters need snaking.\n",
      "\n",
      "Marked Sentence: OK, thanks.\n",
      "(to Go)\n",
      "Bleecker’ soutside.\n",
      "\n",
      "Marked Sentence: GO\n",
      "You are way too into that cat.\n",
      "\n",
      "Marked Sentence: Heheads tothe door, points atthe LIFE board.\n",
      "\n",
      "Marked Sentence: NICK (CONT’D)\n",
      "Tell mehowitends.\n",
      "\n",
      "Marked Sentence: Nick scoops him up, heads tothe FRONT\n",
      "DOOR, which isGAPING WIDE OPEN.\n",
      "Marked Sentence: Nick stops inhis tracks.\n",
      "\n",
      "Marked Sentence: Amy?\n",
      "Wefollow Nick asheheads upthestairs.\n",
      "\n",
      "Marked Sentence: Aniron sits onanironing board, pretty DRESS\n",
      "next toit.\n",
      "Marked Sentence: HALLWAY -UPSTAIRS ROOMS -DAY 15\n",
      "Nick proceeds—quickly—down the hallway, peering into doors:\n",
      "\n",
      "Marked Sentence: Nick goes\n",
      "back downstairs, into:\n",
      "16 INT.\n",
      "Marked Sentence: DINING ROOM -DAY 16\n",
      "Two placemats onthe shiny table.\n",
      "\n",
      "Marked Sentence: KITCHEN -DAY 18\n",
      "Nick runs back through the DINING ROOM, into the: *GG -Blue Draft -8/29/13\n",
      "Marked Sentence: LIVING ROOM -DAY 19\n",
      "Nick stops short.\n",
      "Marked Sentence: The carpet iscovered with GLASS SHARDS\n",
      "from the overturned coffee table.\n",
      "Marked Sentence: END TABLES are SMASHED; an\n",
      "OTTOMAN isUPSIDE DOWN.\n",
      "Marked Sentence: I’m Detective Rhonda\n",
      "Boney andthis isOfficer James\n",
      "Gilpin.\n",
      "Marked Sentence: Weunderstand there are\n",
      "concerns about your wife?\n",
      "\n",
      "Marked Sentence: Icame home to\n",
      "this.\n",
      "\n",
      "Marked Sentence: Hard toread ifthey’re\n",
      "impressed ornot.\n",
      "Marked Sentence: BONEY takes aYELLOW POST-IT and places it\n",
      "onthe MANTEL below three upright photo FRAMES.\n",
      "\n",
      "Marked Sentence: I’m not someone whohits the panic\n",
      "button, but-It’s weird, right?\n",
      "Marked Sentence: They speak intime tothestair steps.\n",
      "\n",
      "Marked Sentence: Weused to\n",
      "live inNew York.\n",
      "Marked Sentence: BONEY\n",
      "Why’d y’all come back here?\n",
      "NICK\n",
      "Mymom got sick.\n",
      "\n",
      "Marked Sentence: She’s dead.\n",
      "\n",
      "Marked Sentence: UPSTAIRS HALLWAY -DAY 23\n",
      "Boney reaches the landing, eyes Nick like apatient mom.\n",
      "\n",
      "Marked Sentence: Now Iown The Bar, downtown.\n",
      "Marked Sentence: With\n",
      "mytwin sister, Margo.\n",
      "\n",
      "Marked Sentence: One small corner isdedicated toakids’ book series, AMAZING\n",
      "AMY.\n",
      "Marked Sentence: Photos ofAmy, atall ages, with her parents, REND and\n",
      "MARYBETH, infront ofposters for the books.\n",
      "\n",
      "Marked Sentence: NICK\n",
      "Soshould Ibecon(cerned)—\n",
      "BONEY\n",
      "(studying apicture)\n",
      "Iremember these books.\n",
      "\n",
      "Marked Sentence: CLOSEUP ofadual frame: AMAZING AMY, the iconic cartoon\n",
      "drawing, isgrinning from one side.\n",
      "Marked Sentence: The eraser topper isaBRIDE with VEIL.\n",
      "Marked Sentence: With me—regular, flawed, Real\n",
      "Amy—jealous, asalways, ofthe\n",
      "golden child.\n",
      "Marked Sentence: Who isgetting fucking\n",
      "married.\n",
      "NICK and Amy aretight together.\n",
      "Marked Sentence: AMY\n",
      "Perfect, time for aquick tour of\n",
      "myfailings.\n",
      "\n",
      "Marked Sentence: Stop infront ofa\n",
      "poster of: gradeschool AMAZING AMY holding aCELLO.\n",
      "Marked Sentence: *\n",
      "They continue their tour.\n",
      "\n",
      "Marked Sentence: Puddles made her *\n",
      "more relatable.\n",
      "Marked Sentence: *\n",
      "They stop infront\n",
      "Marked Sentence: ofthe biggest poster: Amazing Amy, ina *\n",
      "bridal veil, aBLAND GROOM next toher.\n",
      "Marked Sentence: Inthe center ofthe limp party, RAND and MARYBETH, 60s,\n",
      "cheerily hand out commemorative PENS-identical tothe one Amy\n",
      "used for her DIARY.\n",
      "Marked Sentence: RAND\n",
      "(to Amy)\n",
      "\n",
      "Marked Sentence: Hey, sweetheart, this isabig\n",
      "night for your mom.\n",
      "Marked Sentence: Itwould mean\n",
      "somuch toherifyou’d talk toa\n",
      "few reporters.\n",
      "Marked Sentence: People want tohear from you.\n",
      "\n",
      "Marked Sentence: Fifteen minutes, tops!\n",
      "\n",
      "Marked Sentence: AMY\n",
      "This iswhy Ihave mytrust fund,\n",
      "myBrooklyn brownstone.\n",
      "Marked Sentence: Your parents plagiarized your\n",
      "childhood.\n",
      "\n",
      "Marked Sentence: AMY\n",
      "No, they improved upon it, and then\n",
      "peddled ittothe masses.\n",
      "Marked Sentence: MARYBE TH\n",
      "Ithought you were going towear\n",
      "white tomatch the wedding theme.\n",
      "\n",
      "Marked Sentence: Tip ofmytongue...\n",
      "\n",
      "Marked Sentence: (toNick)\n",
      "Ilove having strangers pick atmy\n",
      "scabs.\n",
      "\n",
      "Marked Sentence: -BAR CORNER -NIGHT 29\n",
      "Amy, standing atacocktail table, deals with amontage of\n",
      "New York media types.\n",
      "Marked Sentence: EARNEST GIRL\n",
      "I’m curious whether it’s difficult\n",
      "for you towatch Amazing Amy\n",
      "heading down theaisle\n",
      "FASHIONISTA\n",
      "-and this big party celebrating\n",
      "this fictional wedding-\n",
      "NERVOUS INTERN\n",
      "\n",
      "Marked Sentence: AMY prepares tobeamused.\n",
      "Marked Sentence: *\n",
      "NICK\n",
      "Isittrue that during the course\n",
      "ofyour relationship, you have\n",
      "performed such gracious gestures as\n",
      "(checking notes)\n",
      "not correcting Nick when he\n",
      "pronounced quinoa askw±n—o—a. *\n",
      "AMY\n",
      "Anunderstandable mistake.\n",
      "\n",
      "Marked Sentence: NICK\n",
      "Touché.\n",
      "\n",
      "Marked Sentence: AMY\n",
      "Ithink it’s pronounced tow—chay.\n",
      "NICK\n",
      "(laughing)\n",
      "\n",
      "Marked Sentence: You also manage toappear surprised\n",
      "and delighted when Nick’s elderly\n",
      "mother breaks into “New York, New\n",
      "York” every.. .time..\n",
      "Marked Sentence: You are incredibly smart\n",
      "but entirely unsnobby.\n",
      "Marked Sentence: Gilpin gives abored grunt: hecouldn’t •care less.\n",
      "BONEY (CONT’D)\n",
      "\n",
      "Marked Sentence: Ifthis girl doesn’t show\n",
      "up..\n",
      "Marked Sentence: .this could get out ofhand.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "OK, so: Beautiful wife, handsome\n",
      "husband\n",
      "GILPIN\n",
      "Wife goes missing onher\n",
      "anniversary—\n",
      "BONEY\n",
      "—turns out she’s the star ofabook\n",
      "series every woman inthe country\n",
      "read asakid.\n",
      "\n",
      "Marked Sentence: Let’s stay onour toes.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "Nick, this isSteve Eckert.\n",
      "Marked Sentence: He’s\n",
      "going totake aswab ofyour cheek\n",
      "and ahand swipe ifthat’s ok.\n",
      "NICK\n",
      "\n",
      "Marked Sentence: This isfor?\n",
      "GILPIN\n",
      "Gunshot residue, DNA.\n",
      "\n",
      "Marked Sentence: Now, normally, wewouldn’t treat\n",
      "this asamissing persons case so\n",
      "quick.\n",
      "Marked Sentence: We’d tell you tocall back\n",
      "in24hours.\n",
      "Marked Sentence: But given the scene in\n",
      "the house and given our spike in\n",
      "violent crime oflate, we’re going\n",
      "totake this very, very seriously.\n",
      "\n",
      "Marked Sentence: You got somewhere tostay?\n",
      "NICK\n",
      "Mysister’s.\n",
      "\n",
      "Marked Sentence: We’ll hold\n",
      "apress conference tomorrow.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "Want toget the word out, right?\n",
      "\n",
      "Marked Sentence: Anofficer comes inwith two styrofoam cups ofcoffee, slaps\n",
      "amanila envelope onthe table.\n",
      "Marked Sentence: Ifelt like Iwas inaLaw\n",
      "and Order episode for asecond.\n",
      "Marked Sentence: Now, time isofthe essence in\n",
      "these cases.\n",
      "Marked Sentence: That said, ifyou want\n",
      "tocall alawyer...\n",
      "Marked Sentence: *\n",
      "NICK\n",
      "No, no, whatever you need.\n",
      "Marked Sentence: Woman with all those degrees, what\n",
      "does she do?\n",
      "NICK\n",
      "\n",
      "Marked Sentence: Nick attempts amental inventory.\n",
      "Marked Sentence: This lands aslamely asitsounds—and everyone notes it.\n",
      "\n",
      "Marked Sentence: Iknow afew\n",
      "housewives, that evening glass of\n",
      "wine starts coming atnoon.\n",
      "Marked Sentence: Or\n",
      "prescription pills\n",
      "GILPIN\n",
      "Just last week: soccer mom, nice\n",
      "lady, got her teeth kicked inover *\n",
      "some Oxycontin.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "Ever since the mall went bust, half\n",
      "the town out ofwork.\n",
      "Marked Sentence: BONEY\n",
      "Amy got friends wecantalk to?GG -Yellow Revisions 9/27/13 22.\n",
      "NICK\n",
      "\n",
      "Marked Sentence: No.\n",
      "BONEY\n",
      "Nofriends.\n",
      "Marked Sentence: Inthis whole town.\n",
      "\n",
      "Marked Sentence: She was friendly with mymom...\n",
      "(pause)\n",
      "\n",
      "Marked Sentence: We’ve had aproblem with the\n",
      "homeless inour neighborhood—\n",
      "GILPIN\n",
      "We’ll look into it.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "Soyou gottoThe\n",
      "Marked Sentence: Bar around eleven *\n",
      "today.\n",
      "Marked Sentence: Where were you before then?\n",
      "Just tocross that off.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "Soyour wife has nofriends here.\n",
      "\n",
      "Marked Sentence: Nick isvisibly uncomfortable.\n",
      "Marked Sentence: Well, she’s complicated.\n",
      "Marked Sentence: Boney puts her hand onhis toget him tostop the squeaking.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "You don’t know ifshe has friends, *\n",
      "you don’t know how she spends her\n",
      "days, you don’t know her blood\n",
      "type?\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "Can they get here intime for the\n",
      "press conference tomorrow?\n",
      "NICK\n",
      "Ihaven’t called them yet.\n",
      "\n",
      "Marked Sentence: GILPIN\n",
      "Should Iknow mywife’s blood type?\n",
      "32 INT.\n",
      "Marked Sentence: Wehear MARYBETH’s TONE onthe other end: FEMALE; ANGRY.\n",
      "\n",
      "Marked Sentence: ..at\n",
      "this point they’re taking itvery\n",
      "seriously.\n",
      "Marked Sentence: NICK (CONT’D)\n",
      "Mymother-in-law would like to\n",
      "speak with you.\n",
      "\n",
      "Marked Sentence: BONEY takes the phone and NICK walks down thehail,\n",
      "chastened, ANGRY.\n",
      "Marked Sentence: BILL DUNNE (0.S.)\n",
      "Don’t want tobehere.\n",
      "\n",
      "Marked Sentence: NICK stops inhis tracks, listens.\n",
      "Marked Sentence: Peers into aholding room.\n",
      "\n",
      "Marked Sentence: BILL DUNNE, 60s, bedraggled, ismuttering tohimself while a\n",
      "quietly FURIOUS FEMALE officer waits with him.\n",
      "\n",
      "Marked Sentence: 33 *\n",
      "BILL DUNNE\n",
      "Iwant togohome.\n",
      "\n",
      "Marked Sentence: This ismydad.\n",
      "Marked Sentence: I’ve been here talking toyour\n",
      "detectives.\n",
      "Marked Sentence: Theofficer begins tosoften-\n",
      "BILL DUNNE\n",
      "Bitch.\n",
      "\n",
      "Marked Sentence: FEMALE OFFICER\n",
      "Your father wandered out ofComfort\n",
      "Hill this morning.\n",
      "Marked Sentence: Disoriented.\n",
      "\n",
      "Marked Sentence: FEMALE OFFICER\n",
      "Sir, please don’t take that tone\n",
      "with me.\n",
      "\n",
      "Marked Sentence: BONEY isrevealed tobeinthe doorway, listening.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "You want todrive him home?\n",
      "34 EXT.\n",
      "Marked Sentence: 34 *\n",
      "BONEY walks NICK tothe EXIT.\n",
      "Marked Sentence: He’s always been amisogynist *\n",
      "asshole.\n",
      "Marked Sentence: Not since Iwas 10and mymom *\n",
      "finally divorced his ass.\n",
      "Marked Sentence: Tomorrow will belong.\n",
      "\n",
      "Marked Sentence: Two hours *\n",
      "there—someone had tohave seen him.\n",
      "\n",
      "Marked Sentence: *\n",
      "BONEY\n",
      "Andlet’s check into our guy here.\n",
      "\n",
      "Marked Sentence: CAR -NIGHT 35\n",
      "NICK and his DAD drive SILENTLY through the town.\n",
      "Marked Sentence: Nick\n",
      "reaches across his DAD and removes from his GLOVEBOX aCHEAPO\n",
      "DISPOSABLE phone.\n",
      "Marked Sentence: Helps his\n",
      "DAD out and inside.\n",
      "Marked Sentence: Returns tocar inseconds: Fastest drop-\n",
      "off ever.\n",
      "Marked Sentence: SOMEWHERE -SOMETIME 37\n",
      "Wesee asouvenir BIG APPLE penwriting across the DIARY—date\n",
      "atthe top: July 5,2009.\n",
      "Marked Sentence: Everyone told us—and told usand\n",
      "told us—marriage ishard work.\n",
      "\n",
      "Marked Sentence: NEW YORK BOOKSTORE -ESTABLISHING\n",
      "Marked Sentence: NEW YORK BOOKSTORE -STACKS -DAY 39\n",
      "Nick iswearing abackpack, holding anAmy-blue CLUE ashe\n",
      "makes his way; Amy follows, all grins.\n",
      "\n",
      "Marked Sentence: and *\n",
      "only Elizabeth Bennet understood\n",
      "you.\n",
      "\n",
      "Marked Sentence: AMY\n",
      "Technically we’re supposed tofuck\n",
      "atthe next stop.\n",
      "Marked Sentence: AMY\n",
      "We’ve never fucked inabookstore.\n",
      "Marked Sentence: BOOKSTORE -STACKS -DAY 40\n",
      "Abookshelf: Packed with books.\n",
      "Marked Sentence: One tumbles tothefloor.\n",
      "\n",
      "Marked Sentence: Three atonce asahand busts through: Amy\n",
      "trying toget agrip.\n",
      "Marked Sentence: BAR -AFTERNOON 41\n",
      "Nick and Amy, post-glow, clink glasses and swallow.\n",
      "\n",
      "Marked Sentence: AMY\n",
      "Idragged you into the ladies’ room\n",
      "onour second date.\n",
      "\n",
      "Marked Sentence: And just gotbetter.\n",
      "\n",
      "Marked Sentence: DIM SUM RESTAURANT -ESTABLISHING\n",
      "Marked Sentence: DIM SUM RESTAURANT -NIGHT 43\n",
      "The table isstrewn with dishes, desserts, drinks.\n",
      "Marked Sentence: The waiter approaches with agift box, sets itonthetable.\n",
      "\n",
      "Marked Sentence: AMY\n",
      "Year Two, cotton.\n",
      "\n",
      "Marked Sentence: Nick opens the top, peers in.\n",
      "Marked Sentence: AMY (CONT’D)\n",
      "Because, wehad that joke, that our\n",
      "sex was too good for mere—\n",
      "Hepulls out luxurious deep blue sheets.\n",
      "Marked Sentence: Sometimes Iwant topunch usinthe\n",
      "face we’re socute.\n",
      "\n",
      "Marked Sentence: She tucks the sheets into the couch.\n",
      "\n",
      "Marked Sentence: NICK\n",
      "Idon’t need alawyer.\n",
      "\n",
      "Marked Sentence: GO\n",
      "Did they ask you personal stuff?\n",
      "About Amy?GG -Blue\n",
      "Marked Sentence: They asked why she has nofriends\n",
      "here.\n",
      "\n",
      "Marked Sentence: Ijust said she was complicated.\n",
      "\n",
      "Marked Sentence: GO\n",
      "Nick, everyone knows “complicated” *\n",
      "iscode forbitch.\n",
      "\n",
      "Marked Sentence: It *\n",
      "just seems like the kind ofthing\n",
      "that would happen to?~rny.\n",
      "Marked Sentence: Gotosses apillow atNick, waits for areaction.\n",
      "Marked Sentence: DUNNE HOUSE -NIGHT 46\n",
      "BONEY isdrinking ahuge COFFEE asshe and GILPIN walk toward\n",
      "the house.\n",
      "Marked Sentence: Wecan see ahalf block away, NOELLE HAWTHORNE,\n",
      "PREGNANT, towing identically dressed toddler TRIPLETS.\n",
      "\n",
      "Marked Sentence: I’d love totalk with\n",
      "you, thank you.\n",
      "Marked Sentence: DUNNE LIVING ROOM —NIGHT 47\n",
      "Ahalf dozen officers are onscene: photos, fingerprints.\n",
      "\n",
      "Marked Sentence: *\n",
      "OFFICER\n",
      "(motioning tocloset)\n",
      "\n",
      "Marked Sentence: BONEY heads into thewalk-in, dresses andshirts swaying as\n",
      "she passes.\n",
      "Marked Sentence: GO’S LIVING ROOM -MORNING 49\n",
      "NICK isasleep onthe couch, anempty bottle ofbourbon next\n",
      "tohim.\n",
      "Marked Sentence: Nick takes them silently, guzzles the Coke, checks his watch.\n",
      "\n",
      "Marked Sentence: Ishould shower.\n",
      "\n",
      "Marked Sentence: You want tolook like *\n",
      "you’ve been upall night.\n",
      "Marked Sentence: Becareful today, OK?\n",
      "NICK\n",
      "\n",
      "Marked Sentence: That’s aweird thing tosay.\n",
      "\n",
      "Marked Sentence: GO\n",
      "When you’re upset, youbottle up.\n",
      "\n",
      "Marked Sentence: 33.\n",
      "GO\n",
      "Orelse you swing into your Mama’s *\n",
      "boy charm offensive—it can feel *\n",
      "glib.\n",
      "\n",
      "Marked Sentence: NICK\n",
      "Great, I’ll try tobalance onthe\n",
      "exact edge ofyour emotional razor.\n",
      "\n",
      "Marked Sentence: RAND\n",
      "(toMarybeth)\n",
      "\n",
      "Marked Sentence: MARYBETH\n",
      "Iknew you shouldn’t have moved *\n",
      "back here.\n",
      "Marked Sentence: Together.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "They get along?\n",
      "GO\n",
      "Honestly, here’s the secret to\n",
      "Nick.\n",
      "Marked Sentence: 54\n",
      "BONEY leads the ELLIOTTS and NICK into aroom ofaHALF DOZEN\n",
      "BORED LOCAL REPORTERS:\n",
      "Marked Sentence: Everyone isextremely attentive.\n",
      "\n",
      "Marked Sentence: Weaskfor anyone\n",
      "who may have knowledge ofwhat has\n",
      "happened toher tocome forward.\n",
      "\n",
      "Marked Sentence: RAND\n",
      "Amy isour only child.\n",
      "Marked Sentence: She returned here to\n",
      "her husband’s hometown, and she\n",
      "made alife inher adopted home.\n",
      "\n",
      "Marked Sentence: Now Amy needs your help.\n",
      "Marked Sentence: Nick and theElliotts pause for afew photos.\n",
      "Marked Sentence: APHOTOG asks Nick to\n",
      "pose next toAmy’s photo: ademented PROM SHOT.\n",
      "Marked Sentence: Heglances atGO; she prods him to\n",
      "SMILE.\n",
      "Marked Sentence: 55\n",
      "BONEY, RAND AND MARYBETH and NICK are ataconference table.\n",
      "\n",
      "Marked Sentence: They open one: It’s filled with “AMY FILES”: Photo\n",
      "albums, news clippings, Amazing Amy books.\n",
      "\n",
      "Marked Sentence: MARYBETH\n",
      "Wehave suspects you’ll want to\n",
      "look at, Detective.\n",
      "\n",
      "Marked Sentence: Rand ispulling out photos, notes, from amanila envelope.\n",
      "\n",
      "Marked Sentence: (toNick)\n",
      "Doyou know about Desi Collings?GG —Yellow Revisions 9/27/13 36.\n",
      "\n",
      "Marked Sentence: Aphoto flies into frame:\n",
      "Marked Sentence: BONEY\n",
      "This would behigh school.. .20\n",
      "years ago?\n",
      "MARYBETH\n",
      "Hemoved toSt.\n",
      "Marked Sentence: Louis-that’s just\n",
      "two hours away—\n",
      "NICK\n",
      "Tobefair, he’s from St. Louis—he\n",
      "moved back.\n",
      "Marked Sentence: RAND\n",
      "Wealso have Tommy O’Hara.\n",
      "Marked Sentence: This was\n",
      "only eight years ago inNew York.\n",
      "\n",
      "Marked Sentence: She broke upwith him—he got very\n",
      "physical.\n",
      "Marked Sentence: Idid not know this.\n",
      "\n",
      "Marked Sentence: BONEY\n",
      "Imagine our confusion: missing\n",
      "persons case, and here wefind an\n",
      "envelope marked CLUE.\n",
      "\n",
      "Marked Sentence: For our anniversary Amy always did *\n",
      "this treasure hunt— *\n",
      "BONEY\n",
      "Hoping you cantell mewhat this *\n",
      "means.\n",
      "\n",
      "Marked Sentence: You want tosolve mywife’s\n",
      "treasure hunt?\n",
      "BONEYIt’ll help ustrack Amy’s movements *\n",
      "before she disappeared: Where she\n",
      "went, who she might have seen.\n",
      "Marked Sentence: *\n",
      "Hetakes the clue, doubtfully, dreadfully, and reads.\n",
      "\n",
      "Marked Sentence: “Although this spot couldn’t be~ *\n",
      "tighter/it’s acozy room for my *\n",
      "favorite writer” Ithink Iknow *\n",
      "this.\n",
      "\n",
      "Marked Sentence: COLLEGE -DAY 58\n",
      "NICK and BONEY weave past bored summer-school kids.\n",
      "Marked Sentence: NICK\n",
      "reaches hisoffice, finds his key, steps over apile ofMAIL.\n",
      "\n",
      "Marked Sentence: Hegives aglance toBONEY before touching it.\n",
      "\n",
      "Marked Sentence: Hepicks upapair ofSCISSORS that sit next toaMATCHING\n",
      "STAPLER and opens it.\n",
      "Marked Sentence: Boney reads over his shoulder.\n",
      "\n",
      "Marked Sentence: Let’s head onover to\n",
      "thelittle brown house.\n",
      "\n",
      "Marked Sentence: We’ll play hot, doting husband and\n",
      "sweet loving spouse.\n",
      "\n",
      "Marked Sentence: Onthe shelves: the usual Modern Male Canon suspects:\n",
      "Franzen, Lethem, Chabon, Eggers.\n",
      "Marked Sentence: NICK looks STUNNED.\n",
      "Marked Sentence: BONEY slips the undies into anevidence bag.\n",
      "Marked Sentence: Boney nods toward the CLUE.\n",
      "\n",
      "Marked Sentence: This isanobvious stonewall.\n",
      "Marked Sentence: Date: October\n",
      "11, 2009.\n",
      "Marked Sentence: I’ve sworn never tobeone ofthose *\n",
      "wives.\n",
      "Marked Sentence: BROOKLYN BROWNSTONE BEDROOM-\n",
      "Marked Sentence: BROOKLYN BROWNSTONE LIVING ROOM- PRE-DAWN B61 *\n",
      "Amy crosses tothe door, opens ittosee Nick, drunk, *\n",
      "disheveled, trying toget his key in.\n",
      "Marked Sentence: *\n",
      "Hestarts toexplain.\n",
      "Marked Sentence: BROOKLYN BROWNSTONE BEDROOM-\n",
      "Marked Sentence: PRE-DAWN 61 *\n",
      "AMY and NICK, post-sex, inabigVictorian bedroom—BEAUTIFUL.\n",
      "Marked Sentence: Amy makes asweeping gesture: everyone outside their window.\n",
      "\n",
      "Marked Sentence: Wives\n",
      "whotreat their men like hapless *\n",
      "puppies: tobetrained and broken.\n",
      "\n",
      "Marked Sentence: Nick knows this game—defining themselves bywho they aren’t.\n",
      "\n",
      "Marked Sentence: NICK\n",
      "Husbands who treat their wives like\n",
      "eccentric dictators: tobeappeased *\n",
      "and contained.\n",
      "Marked Sentence: *\n",
      "ANY\n",
      "Couples whose conversations revolve\n",
      "around to-do lists.\n",
      "\n",
      "Marked Sentence: AMY\n",
      "(shrugging itoff)\n",
      "\n",
      "Marked Sentence: Ahuge weight comes off Nick.\n",
      "\n",
      "Marked Sentence: They’re indebt upto\n",
      "their ears.\n",
      "NICK\n",
      "Ohno,that’s awful.\n",
      "\n",
      "Marked Sentence: AMY\n",
      "They heed toborrow from mytrust\n",
      "fund.\n",
      "\n",
      "Marked Sentence: This iswhere you say, “Everything\n",
      "else isbackground noise.\n",
      "Marked Sentence: ”\n",
      "NICK\n",
      "Amy, ifI’mlaid off and you’re\n",
      "laid off\n",
      "AMY\n",
      "Itold them I’d doit.\n",
      "Marked Sentence: Without even talking tome?\n",
      "\n",
      "Marked Sentence: Ahard moment.\n",
      "Marked Sentence: Heputs afinger tohis chin: Their old\n",
      "CODE.\n",
      "Marked Sentence: Begins driving.\n",
      "Marked Sentence: Assoon ashe’s out of *\n",
      "thelot, hepulls out his DISPOSABLE.\n",
      "Marked Sentence: *\n",
      "Nick drives into arun-down neighborhood.\n",
      "Marked Sentence: Let’s head on\n",
      "over tothelittle brown house.\n",
      "\n",
      "Marked Sentence: BILL DUNNE’S HOUSE -NIGHT 65\n",
      "Hepulls uptoaBLUE HOUSE.\n",
      "Marked Sentence: We’ll play hot, doting husband and\n",
      "sweet loving spouse.\n",
      "\n",
      "Marked Sentence: Hepounds afew buttons.\n",
      "Marked Sentence: This *\n",
      "issounnecessary.\n",
      "Marked Sentence: Flashing cop lights inthe window.\n",
      "Marked Sentence: *\n",
      "(into her walkie)\n",
      "We’re good.\n",
      "\n",
      "Marked Sentence: BONEY (CONT’D)\n",
      "Your dad’s house, right?\n",
      "NICK\n",
      "Are you following me?\n",
      "\n",
      "Marked Sentence: She starts tonose around.\n",
      "Marked Sentence: BONEY\n",
      "Thought maybe this was thelittle\n",
      "brown house.\n",
      "Marked Sentence: -NIGHT 68\n",
      "NICK pulls uptoGO’s.\n",
      "Marked Sentence: I need tobepunished and by *\n",
      "punished Imean had.\n",
      "Marked Sentence: Hetries tocalm himself.\n",
      "Marked Sentence: It’s where you keep goodies for *\n",
      "anniversary five *\n",
      "Soopen the door—and look alive.\n",
      "Marked Sentence: SOMEWHERE -SOMETIME 69\n",
      "Apen—Bic, gnarled atthe top—cursiving over aDIARY.\n",
      "Marked Sentence: Wesee the words aswehear:\n",
      "AMY (V.0.)\n",
      "Want totest your marriage for weak\n",
      "spots?\n",
      "Marked Sentence: BROOKLYN BROWNSTONE -DAY 70\n",
      "She opens drapes, picks upbeer cans and old takeout.\n",
      "\n",
      "Marked Sentence: DEN -DAY 71\n",
      "AMY opens the door toreveal NICK inhis boxers, beer cans\n",
      "next tohim.\n",
      "Marked Sentence: She sees ashopping bag; starts\n",
      "pulling out the contents: alaptop, Ipod, adozen PS2 gaines.\n",
      "\n",
      "Marked Sentence: Ifelt Ineeded toshoot something.\n",
      "Marked Sentence: What’s the laptop for?\n",
      "NICK\n",
      "Laptopping.\n",
      "Marked Sentence: AMY\n",
      "Why are you throwing that inmy\n",
      "face again?GG -Yellow Revisions 9/27/13 45.\n",
      "NICK\n",
      "\n",
      "Marked Sentence: It’s easy tothrow.\n",
      "\n",
      "Marked Sentence: It’s like\n",
      "you’re daring metobesomeone I\n",
      "don’t want tobe.\n",
      "Marked Sentence: I’m notthat\n",
      "person.\n",
      "Marked Sentence: Abeat.\n",
      "Marked Sentence: Hetakes abreath.\n",
      "\n",
      "Marked Sentence: *\n",
      "Iworked all these shitty jobs soI *\n",
      "could gotocollege, and get ajob.\n",
      "Marked Sentence: Idon’t know how tonot have ajob.\n",
      "Marked Sentence: Now: I’m *\n",
      "beholden toyou.\n",
      "Marked Sentence: Suddenly Iknew everything was\n",
      "about toget worse.\n",
      "\n",
      "Marked Sentence: 72 EXT. DRURY LODGE -MORNING 72\n",
      "ACLOSEUP ofAmy’s photo onahomemade\n",
      "Marked Sentence: Thechild drags it\n",
      "through abusy parking lot: Two newsvans, SUV5, station\n",
      "wagons.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import PyPDF2\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "\n",
    "# Step 1: Load Spacy Model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Step 2: Load Pre-trained Word2Vec Model\n",
    "model = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "# Step 3: Expand Keywords Using Word2Vec\n",
    "def expand_keywords(keywords, model, topn=10):\n",
    "    expanded_keywords = set(keywords)\n",
    "    for word in keywords:\n",
    "        if word in model:\n",
    "            similar_words = model.most_similar(word, topn=topn)\n",
    "            expanded_keywords.update([w for w, score in similar_words])\n",
    "    return list(expanded_keywords)\n",
    "\n",
    "# Initial Keyword Lists\n",
    "female_keywords = [\"woman\", \"women\", \"female\", \"girl\", \"girls\", \"lady\", \"ladies\", \"wife\", \"wives\", \"mother\", \"mothers\", \"daughter\", \"daughters\"]\n",
    "female_weakness_keywords = [\n",
    "    \"needs\", \"depends on\", \"relies on\", \"requires help\", \"seeks help\", \"pleads\", \"asks for help\", \"depends upon\",\n",
    "    \"submits\", \"obeys\", \"yields\", \"follows\", \"compliant\", \"docile\", \"subservient\", \"acquiesces\",\n",
    "    \"hysterical\", \"emotional\", \"overwhelmed\", \"fragile\", \"vulnerable\", \"sensitive\", \"teary\", \"upset\",\n",
    "    \"weak\", \"delicate\", \"frail\", \"helpless\", \"powerless\", \"feeble\", \"timid\", \"faint\",\n",
    "    \"unable\", \"powerless\", \"helpless\", \"victim\", \"trapped\", \"cornered\", \"defenseless\", \"dependent\",\n",
    "    \"housewife\", \"caregiver\", \"nurturer\", \"homebound\", \"domestic\", \"motherly\", \"housebound\", \"homemaker\"\n",
    "]\n",
    "\n",
    "# Expand Keyword Lists\n",
    "expanded_female_keywords = expand_keywords(female_keywords, model)\n",
    "expanded_female_weakness_keywords = expand_keywords(female_weakness_keywords, model)\n",
    "\n",
    "# Step 4: Load and Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(min(50, len(reader.pages))):  # Only process the first 50 pages\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"GoneGirl.pdf\")\n",
    "\n",
    "# Step 5: Function to Analyze if a Sentence Contains Both Female and Weakness Keywords\n",
    "def analyze_female_weakness(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    has_female_keyword = any(keyword in sentence.lower() for keyword in expanded_female_keywords)\n",
    "    has_weakness_keyword = any(keyword in sentence.lower() for keyword in expanded_female_weakness_keywords)\n",
    "    \n",
    "    if female_keywords and has_weakness_keyword:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Step 6: Split Text into Sentences and Analyze\n",
    "doc = nlp(pdf_text)\n",
    "female_weakness_results = []\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    if analyze_female_weakness(sentence.text):\n",
    "        female_weakness_results.append({\n",
    "            \"sentence\": sentence.text,\n",
    "            \"classification\": \"Female Weakness\"\n",
    "        })\n",
    "\n",
    "# Step 7: Save the Results to a JSON File\n",
    "with open(\"female_weakness_sentences.json\", \"w\") as json_file:\n",
    "    json.dump(female_weakness_results, json_file, indent=4)\n",
    "\n",
    "# Step 8: Print the Results\n",
    "for result in female_weakness_results:\n",
    "    print(f\"Marked Sentence: {result['sentence']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
